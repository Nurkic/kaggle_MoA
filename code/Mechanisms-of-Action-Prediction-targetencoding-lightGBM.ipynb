{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms-of-Action-Prediction-targetencoding-lightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "train_targets_scored = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "train_targets_nonscored = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "test_features = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "submission = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = pd.concat([train_features, test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "object_cols = [\"cp_type\", \"cp_dose\"]\n",
    "ce_oe = ce.OrdinalEncoder(cols=object_cols, handle_unknown='impute')\n",
    "prep_df = ce_oe.fit_transform(prep_df)\n",
    "train_features = prep_df.iloc[:len(train_features),:]\n",
    "test_features = prep_df.iloc[len(train_features):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoder(\n",
    "        train_X: pd.DataFrame,\n",
    "        train_y: pd.DataFrame,\n",
    "        test: pd.DataFrame,\n",
    "        column_list: list\n",
    ") -> pd.DataFrame:\n",
    "        train_X_te = copy.deepcopy(train_X)\n",
    "        test_X_te = copy.deepcopy(test)\n",
    "        if len(column_list) > 0:\n",
    "            print(\"categorical features:\"+ str(column_list))\n",
    "        else:\n",
    "            print(\"No categorical features\")\n",
    "        for c in column_list:\n",
    "            data_tmp = pd.DataFrame({c: train_X_te[c], \"target\": train_y})\n",
    "            target_mean = data_tmp.groupby(c)[\"target\"].mean()\n",
    "            \"\"\" print(target_mean)\"\"\"\n",
    "            test_X_te[c] = test_X_te[c].map(target_mean).astype(float)\n",
    "\n",
    "            tmp = np.repeat(np.nan, train_X.shape[0])\n",
    "            kf_encoding = KFold(n_splits=4, shuffle=True, random_state=72)\n",
    "            for idx_1, idx_2 in kf_encoding.split(train_X_te):\n",
    "                target_mean = data_tmp.iloc[idx_1].groupby(c)[\"target\"].mean()\n",
    "\n",
    "                tmp[idx_2] = train_X_te[c].iloc[idx_2].map(target_mean)\n",
    "\n",
    "            train_X_te[c] = tmp\n",
    "\n",
    "        return train_X_te, test_X_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train models and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "FOLD_NUM = 5\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "target_cols = [c for c in train_targets_scored.columns if c != \"sig_id\"]\n",
    "oof = train_targets_scored.copy()\n",
    "num_round = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "#'boosting_type': 'gbdt',\n",
    "'objective': 'binary',\n",
    "#'lambda_l1': 0.001, \n",
    "#'lambda_l2': 0.001,\n",
    "'num_leaves': 50, \n",
    "'max_depth': 6,\n",
    "#'feature_fraction': 0.4,\n",
    "#'subsample': 0.4, \n",
    "#'min_child_samples': 10,\n",
    "'learning_rate': 0.01,\n",
    "#'num_iterations': 100, #700\n",
    "'early_stopping_rounds': 100,\n",
    "'random_state': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgbm(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    target_col: str):\n",
    "    \n",
    "    X_train = X_train.drop([\"sig_id\"], axis=1)\n",
    "    y_train = train_targets_scored[target_col]\n",
    "    X_test = X_test.drop([\"sig_id\"], axis=1)\n",
    "\n",
    "    y_preds = []\n",
    "    models = []\n",
    "    oof_train = np.zeros((len(X_train),))\n",
    "\n",
    "    for fold_id, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "        X_tr = X_train.loc[train_index, :]\n",
    "        X_val = X_train.loc[valid_index, :]\n",
    "        y_tr = y_train[train_index]\n",
    "        y_val = y_train[valid_index]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_tr,\n",
    "                                y_tr,\n",
    "                                categorical_feature=object_cols)\n",
    "\n",
    "        lgb_eval = lgb.Dataset(X_val,\n",
    "                               y_val,\n",
    "                               reference=lgb_train,\n",
    "                               categorical_feature=object_cols)\n",
    "\n",
    "        model = lgb.train(params,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_train, lgb_eval],\n",
    "                          verbose_eval=10,\n",
    "                          num_boost_round=1000,\n",
    "                          early_stopping_rounds=10)\n",
    "\n",
    "\n",
    "        oof_train[valid_index] = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        \n",
    "        y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "        models.append(model)\n",
    "\n",
    "    return oof_train, sum(y_preds) / len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical features:['cp_type', 'cp_dose']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimura_sampler/anaconda3/envs/probspace_realestate/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kimura_sampler/anaconda3/envs/probspace_realestate/lib/python3.8/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00236783\tvalid_1's binary_logloss: 0.0068585\n",
      "[20]\ttraining's binary_logloss: 0.00181572\tvalid_1's binary_logloss: 0.00688485\n",
      "[30]\ttraining's binary_logloss: 0.00150247\tvalid_1's binary_logloss: 0.00691576\n",
      "[40]\ttraining's binary_logloss: 0.00128277\tvalid_1's binary_logloss: 0.00695037\n",
      "[50]\ttraining's binary_logloss: 0.00111277\tvalid_1's binary_logloss: 0.00698997\n",
      "[60]\ttraining's binary_logloss: 0.000976128\tvalid_1's binary_logloss: 0.00702704\n",
      "[70]\ttraining's binary_logloss: 0.000863108\tvalid_1's binary_logloss: 0.00702334\n",
      "[80]\ttraining's binary_logloss: 0.00076729\tvalid_1's binary_logloss: 0.00703847\n",
      "[90]\ttraining's binary_logloss: 0.000684898\tvalid_1's binary_logloss: 0.00706433\n",
      "[100]\ttraining's binary_logloss: 0.000613379\tvalid_1's binary_logloss: 0.0070939\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00479453\tvalid_1's binary_logloss: 0.00681599\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00266577\tvalid_1's binary_logloss: 0.00530819\n",
      "[20]\ttraining's binary_logloss: 0.00202516\tvalid_1's binary_logloss: 0.0053103\n",
      "[30]\ttraining's binary_logloss: 0.00166892\tvalid_1's binary_logloss: 0.00531684\n",
      "[40]\ttraining's binary_logloss: 0.00142331\tvalid_1's binary_logloss: 0.0052905\n",
      "[50]\ttraining's binary_logloss: 0.00123901\tvalid_1's binary_logloss: 0.00529897\n",
      "[60]\ttraining's binary_logloss: 0.0010892\tvalid_1's binary_logloss: 0.00529756\n",
      "[70]\ttraining's binary_logloss: 0.000964934\tvalid_1's binary_logloss: 0.00529569\n",
      "[80]\ttraining's binary_logloss: 0.000859801\tvalid_1's binary_logloss: 0.00529897\n",
      "[90]\ttraining's binary_logloss: 0.000768595\tvalid_1's binary_logloss: 0.00531232\n",
      "[100]\ttraining's binary_logloss: 0.000688966\tvalid_1's binary_logloss: 0.00532944\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00528055\tvalid_1's binary_logloss: 0.00528727\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00233804\tvalid_1's binary_logloss: 0.00841953\n",
      "[20]\ttraining's binary_logloss: 0.00175009\tvalid_1's binary_logloss: 0.00847221\n",
      "[30]\ttraining's binary_logloss: 0.00143684\tvalid_1's binary_logloss: 0.00851535\n",
      "[40]\ttraining's binary_logloss: 0.00121976\tvalid_1's binary_logloss: 0.00850614\n",
      "[50]\ttraining's binary_logloss: 0.00105637\tvalid_1's binary_logloss: 0.00853672\n",
      "[60]\ttraining's binary_logloss: 0.00092529\tvalid_1's binary_logloss: 0.00858954\n",
      "[70]\ttraining's binary_logloss: 0.000816531\tvalid_1's binary_logloss: 0.00863357\n",
      "[80]\ttraining's binary_logloss: 0.000724518\tvalid_1's binary_logloss: 0.00868252\n",
      "[90]\ttraining's binary_logloss: 0.000645269\tvalid_1's binary_logloss: 0.00874113\n",
      "[100]\ttraining's binary_logloss: 0.000576258\tvalid_1's binary_logloss: 0.00878061\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00472976\tvalid_1's binary_logloss: 0.0083773\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00241597\tvalid_1's binary_logloss: 0.00687358\n",
      "[20]\ttraining's binary_logloss: 0.00184332\tvalid_1's binary_logloss: 0.00690013\n",
      "[30]\ttraining's binary_logloss: 0.00152531\tvalid_1's binary_logloss: 0.00687355\n",
      "[40]\ttraining's binary_logloss: 0.00130226\tvalid_1's binary_logloss: 0.00688003\n",
      "[50]\ttraining's binary_logloss: 0.00113028\tvalid_1's binary_logloss: 0.00688626\n",
      "[60]\ttraining's binary_logloss: 0.000991331\tvalid_1's binary_logloss: 0.00690091\n",
      "[70]\ttraining's binary_logloss: 0.000876557\tvalid_1's binary_logloss: 0.00685615\n",
      "[80]\ttraining's binary_logloss: 0.000779177\tvalid_1's binary_logloss: 0.00684577\n",
      "[90]\ttraining's binary_logloss: 0.000695429\tvalid_1's binary_logloss: 0.00685286\n",
      "[100]\ttraining's binary_logloss: 0.000622206\tvalid_1's binary_logloss: 0.00685347\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00492669\tvalid_1's binary_logloss: 0.00682253\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00312568\tvalid_1's binary_logloss: 0.0023157\n",
      "[20]\ttraining's binary_logloss: 0.00235044\tvalid_1's binary_logloss: 0.00223158\n",
      "[30]\ttraining's binary_logloss: 0.00193929\tvalid_1's binary_logloss: 0.00214333\n",
      "[40]\ttraining's binary_logloss: 0.00164909\tvalid_1's binary_logloss: 0.00203242\n",
      "[50]\ttraining's binary_logloss: 0.00143636\tvalid_1's binary_logloss: 0.00199205\n",
      "[60]\ttraining's binary_logloss: 0.00126565\tvalid_1's binary_logloss: 0.00195835\n",
      "[70]\ttraining's binary_logloss: 0.00112336\tvalid_1's binary_logloss: 0.0019231\n",
      "[80]\ttraining's binary_logloss: 0.00100243\tvalid_1's binary_logloss: 0.00188688\n",
      "[90]\ttraining's binary_logloss: 0.000898261\tvalid_1's binary_logloss: 0.00185417\n",
      "[100]\ttraining's binary_logloss: 0.000807622\tvalid_1's binary_logloss: 0.00182007\n",
      "[110]\ttraining's binary_logloss: 0.000728009\tvalid_1's binary_logloss: 0.00178444\n",
      "[120]\ttraining's binary_logloss: 0.000657705\tvalid_1's binary_logloss: 0.00176787\n",
      "[130]\ttraining's binary_logloss: 0.000595284\tvalid_1's binary_logloss: 0.00174853\n",
      "[140]\ttraining's binary_logloss: 0.00053973\tvalid_1's binary_logloss: 0.00173698\n",
      "[150]\ttraining's binary_logloss: 0.000490007\tvalid_1's binary_logloss: 0.00172259\n",
      "[160]\ttraining's binary_logloss: 0.000445489\tvalid_1's binary_logloss: 0.00171516\n",
      "[170]\ttraining's binary_logloss: 0.000405191\tvalid_1's binary_logloss: 0.00170934\n",
      "[180]\ttraining's binary_logloss: 0.000368818\tvalid_1's binary_logloss: 0.00170556\n",
      "[190]\ttraining's binary_logloss: 0.000336219\tvalid_1's binary_logloss: 0.00170751\n",
      "[200]\ttraining's binary_logloss: 0.000306652\tvalid_1's binary_logloss: 0.00170644\n",
      "[210]\ttraining's binary_logloss: 0.000279342\tvalid_1's binary_logloss: 0.00170601\n",
      "[220]\ttraining's binary_logloss: 0.00025425\tvalid_1's binary_logloss: 0.00171509\n",
      "[230]\ttraining's binary_logloss: 0.000231921\tvalid_1's binary_logloss: 0.00172543\n",
      "[240]\ttraining's binary_logloss: 0.000211479\tvalid_1's binary_logloss: 0.00173231\n",
      "[250]\ttraining's binary_logloss: 0.000192801\tvalid_1's binary_logloss: 0.0017442\n",
      "[260]\ttraining's binary_logloss: 0.000175966\tvalid_1's binary_logloss: 0.00175276\n",
      "[270]\ttraining's binary_logloss: 0.000160702\tvalid_1's binary_logloss: 0.0017662\n",
      "[280]\ttraining's binary_logloss: 0.000146807\tvalid_1's binary_logloss: 0.00178039\n",
      "[290]\ttraining's binary_logloss: 0.000134095\tvalid_1's binary_logloss: 0.00179513\n",
      "[300]\ttraining's binary_logloss: 0.000122724\tvalid_1's binary_logloss: 0.00180644\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's binary_logloss: 0.000298454\tvalid_1's binary_logloss: 0.00170035\n",
      "categorical features:['cp_type', 'cp_dose']\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00319751\tvalid_1's binary_logloss: 0.00509385\n",
      "[20]\ttraining's binary_logloss: 0.00234229\tvalid_1's binary_logloss: 0.00506767\n",
      "[30]\ttraining's binary_logloss: 0.00195541\tvalid_1's binary_logloss: 0.00506711\n",
      "[40]\ttraining's binary_logloss: 0.00168903\tvalid_1's binary_logloss: 0.00505298\n",
      "[50]\ttraining's binary_logloss: 0.00148022\tvalid_1's binary_logloss: 0.00501904\n",
      "[60]\ttraining's binary_logloss: 0.00130957\tvalid_1's binary_logloss: 0.00500147\n",
      "[70]\ttraining's binary_logloss: 0.00116683\tvalid_1's binary_logloss: 0.00500943\n",
      "[80]\ttraining's binary_logloss: 0.00104485\tvalid_1's binary_logloss: 0.00501546\n",
      "[90]\ttraining's binary_logloss: 0.000936985\tvalid_1's binary_logloss: 0.00503625\n",
      "[100]\ttraining's binary_logloss: 0.000844957\tvalid_1's binary_logloss: 0.00504492\n",
      "[110]\ttraining's binary_logloss: 0.000766001\tvalid_1's binary_logloss: 0.00505825\n",
      "[120]\ttraining's binary_logloss: 0.000697763\tvalid_1's binary_logloss: 0.00505574\n",
      "[130]\ttraining's binary_logloss: 0.000636548\tvalid_1's binary_logloss: 0.00507055\n",
      "[140]\ttraining's binary_logloss: 0.000581244\tvalid_1's binary_logloss: 0.00509213\n",
      "[150]\ttraining's binary_logloss: 0.000529541\tvalid_1's binary_logloss: 0.00511992\n",
      "[160]\ttraining's binary_logloss: 0.000482513\tvalid_1's binary_logloss: 0.00514963\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.00129487\tvalid_1's binary_logloss: 0.00499701\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00243123\tvalid_1's binary_logloss: 0.00997034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's binary_logloss: 0.00179818\tvalid_1's binary_logloss: 0.0100447\n",
      "[30]\ttraining's binary_logloss: 0.00148971\tvalid_1's binary_logloss: 0.0100949\n",
      "[40]\ttraining's binary_logloss: 0.0012776\tvalid_1's binary_logloss: 0.0101784\n",
      "[50]\ttraining's binary_logloss: 0.00111616\tvalid_1's binary_logloss: 0.0102491\n",
      "[60]\ttraining's binary_logloss: 0.000984331\tvalid_1's binary_logloss: 0.010325\n",
      "[70]\ttraining's binary_logloss: 0.00087552\tvalid_1's binary_logloss: 0.0103921\n",
      "[80]\ttraining's binary_logloss: 0.000782081\tvalid_1's binary_logloss: 0.0104816\n",
      "[90]\ttraining's binary_logloss: 0.000700959\tvalid_1's binary_logloss: 0.0105739\n",
      "[100]\ttraining's binary_logloss: 0.000629586\tvalid_1's binary_logloss: 0.0106743\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0049334\tvalid_1's binary_logloss: 0.00992439\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0030805\tvalid_1's binary_logloss: 0.00686536\n",
      "[20]\ttraining's binary_logloss: 0.00219902\tvalid_1's binary_logloss: 0.00685029\n",
      "[30]\ttraining's binary_logloss: 0.00183716\tvalid_1's binary_logloss: 0.00685923\n",
      "[40]\ttraining's binary_logloss: 0.00158376\tvalid_1's binary_logloss: 0.00686736\n",
      "[50]\ttraining's binary_logloss: 0.00139098\tvalid_1's binary_logloss: 0.00689111\n",
      "[60]\ttraining's binary_logloss: 0.00123492\tvalid_1's binary_logloss: 0.00690651\n",
      "[70]\ttraining's binary_logloss: 0.00110157\tvalid_1's binary_logloss: 0.00695243\n",
      "[80]\ttraining's binary_logloss: 0.000988369\tvalid_1's binary_logloss: 0.00700128\n",
      "[90]\ttraining's binary_logloss: 0.000889985\tvalid_1's binary_logloss: 0.00704696\n",
      "[100]\ttraining's binary_logloss: 0.000801903\tvalid_1's binary_logloss: 0.00710008\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00524522\tvalid_1's binary_logloss: 0.00681002\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00297344\tvalid_1's binary_logloss: 0.00533101\n",
      "[20]\ttraining's binary_logloss: 0.00222886\tvalid_1's binary_logloss: 0.00533069\n",
      "[30]\ttraining's binary_logloss: 0.00185928\tvalid_1's binary_logloss: 0.00527883\n",
      "[40]\ttraining's binary_logloss: 0.0015979\tvalid_1's binary_logloss: 0.00528996\n",
      "[50]\ttraining's binary_logloss: 0.00139096\tvalid_1's binary_logloss: 0.00529406\n",
      "[60]\ttraining's binary_logloss: 0.00123008\tvalid_1's binary_logloss: 0.00530502\n",
      "[70]\ttraining's binary_logloss: 0.00109703\tvalid_1's binary_logloss: 0.00532791\n",
      "[80]\ttraining's binary_logloss: 0.00098445\tvalid_1's binary_logloss: 0.00535444\n",
      "[90]\ttraining's binary_logloss: 0.000886706\tvalid_1's binary_logloss: 0.00538352\n",
      "[100]\ttraining's binary_logloss: 0.000801526\tvalid_1's binary_logloss: 0.00541013\n",
      "[110]\ttraining's binary_logloss: 0.000726021\tvalid_1's binary_logloss: 0.00543939\n",
      "[120]\ttraining's binary_logloss: 0.000659792\tvalid_1's binary_logloss: 0.00547124\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.00189006\tvalid_1's binary_logloss: 0.00527782\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00334651\tvalid_1's binary_logloss: 0.00380979\n",
      "[20]\ttraining's binary_logloss: 0.00250412\tvalid_1's binary_logloss: 0.0037916\n",
      "[30]\ttraining's binary_logloss: 0.00209423\tvalid_1's binary_logloss: 0.0037771\n",
      "[40]\ttraining's binary_logloss: 0.00180027\tvalid_1's binary_logloss: 0.00376465\n",
      "[50]\ttraining's binary_logloss: 0.0015782\tvalid_1's binary_logloss: 0.00375661\n",
      "[60]\ttraining's binary_logloss: 0.00139683\tvalid_1's binary_logloss: 0.00375261\n",
      "[70]\ttraining's binary_logloss: 0.0012449\tvalid_1's binary_logloss: 0.00373131\n",
      "[80]\ttraining's binary_logloss: 0.00111768\tvalid_1's binary_logloss: 0.00372171\n",
      "[90]\ttraining's binary_logloss: 0.00100955\tvalid_1's binary_logloss: 0.00371145\n",
      "[100]\ttraining's binary_logloss: 0.000915396\tvalid_1's binary_logloss: 0.00371549\n",
      "[110]\ttraining's binary_logloss: 0.00083249\tvalid_1's binary_logloss: 0.00372254\n",
      "[120]\ttraining's binary_logloss: 0.00075887\tvalid_1's binary_logloss: 0.00372697\n",
      "[130]\ttraining's binary_logloss: 0.000693146\tvalid_1's binary_logloss: 0.00373406\n",
      "[140]\ttraining's binary_logloss: 0.000634211\tvalid_1's binary_logloss: 0.00374777\n",
      "[150]\ttraining's binary_logloss: 0.000580336\tvalid_1's binary_logloss: 0.00375828\n",
      "[160]\ttraining's binary_logloss: 0.000530467\tvalid_1's binary_logloss: 0.00376968\n",
      "[170]\ttraining's binary_logloss: 0.00048435\tvalid_1's binary_logloss: 0.00377811\n",
      "[180]\ttraining's binary_logloss: 0.000441789\tvalid_1's binary_logloss: 0.00379673\n",
      "[190]\ttraining's binary_logloss: 0.00040362\tvalid_1's binary_logloss: 0.00381283\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's binary_logloss: 0.000970535\tvalid_1's binary_logloss: 0.00370958\n",
      "categorical features:['cp_type', 'cp_dose']\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00468045\tvalid_1's binary_logloss: 0.00831409\n",
      "[20]\ttraining's binary_logloss: 0.00337409\tvalid_1's binary_logloss: 0.00835909\n",
      "[30]\ttraining's binary_logloss: 0.00261703\tvalid_1's binary_logloss: 0.00839134\n",
      "[40]\ttraining's binary_logloss: 0.00223781\tvalid_1's binary_logloss: 0.00843131\n",
      "[50]\ttraining's binary_logloss: 0.00194761\tvalid_1's binary_logloss: 0.00847403\n",
      "[60]\ttraining's binary_logloss: 0.00171315\tvalid_1's binary_logloss: 0.00852051\n",
      "[70]\ttraining's binary_logloss: 0.00151758\tvalid_1's binary_logloss: 0.00857129\n",
      "[80]\ttraining's binary_logloss: 0.00135838\tvalid_1's binary_logloss: 0.00862718\n",
      "[90]\ttraining's binary_logloss: 0.00122568\tvalid_1's binary_logloss: 0.00868206\n",
      "[100]\ttraining's binary_logloss: 0.00110629\tvalid_1's binary_logloss: 0.00873411\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00705367\tvalid_1's binary_logloss: 0.00826747\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00508694\tvalid_1's binary_logloss: 0.00542899\n",
      "[20]\ttraining's binary_logloss: 0.00371302\tvalid_1's binary_logloss: 0.00543063\n",
      "[30]\ttraining's binary_logloss: 0.00294543\tvalid_1's binary_logloss: 0.00541671\n",
      "[40]\ttraining's binary_logloss: 0.00249621\tvalid_1's binary_logloss: 0.0054039\n",
      "[50]\ttraining's binary_logloss: 0.00217577\tvalid_1's binary_logloss: 0.00539852\n",
      "[60]\ttraining's binary_logloss: 0.00192056\tvalid_1's binary_logloss: 0.00539718\n",
      "[70]\ttraining's binary_logloss: 0.00170489\tvalid_1's binary_logloss: 0.00540009\n",
      "[80]\ttraining's binary_logloss: 0.00152518\tvalid_1's binary_logloss: 0.00540859\n",
      "[90]\ttraining's binary_logloss: 0.00137024\tvalid_1's binary_logloss: 0.00542118\n",
      "[100]\ttraining's binary_logloss: 0.0012334\tvalid_1's binary_logloss: 0.00543718\n",
      "[110]\ttraining's binary_logloss: 0.00111666\tvalid_1's binary_logloss: 0.00545754\n",
      "[120]\ttraining's binary_logloss: 0.00100998\tvalid_1's binary_logloss: 0.0054804\n",
      "[130]\ttraining's binary_logloss: 0.000916393\tvalid_1's binary_logloss: 0.00550642\n",
      "[140]\ttraining's binary_logloss: 0.000833279\tvalid_1's binary_logloss: 0.00553589\n",
      "[150]\ttraining's binary_logloss: 0.000758953\tvalid_1's binary_logloss: 0.00556826\n",
      "[160]\ttraining's binary_logloss: 0.000692458\tvalid_1's binary_logloss: 0.00559892\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.00192056\tvalid_1's binary_logloss: 0.00539718\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00412631\tvalid_1's binary_logloss: 0.00833123\n",
      "[20]\ttraining's binary_logloss: 0.00305813\tvalid_1's binary_logloss: 0.0082044\n",
      "[30]\ttraining's binary_logloss: 0.00242153\tvalid_1's binary_logloss: 0.00823113\n",
      "[40]\ttraining's binary_logloss: 0.00204795\tvalid_1's binary_logloss: 0.00826463\n",
      "[50]\ttraining's binary_logloss: 0.00177787\tvalid_1's binary_logloss: 0.00830526\n",
      "[60]\ttraining's binary_logloss: 0.00156364\tvalid_1's binary_logloss: 0.00835189\n",
      "[70]\ttraining's binary_logloss: 0.00138469\tvalid_1's binary_logloss: 0.00839611\n",
      "[80]\ttraining's binary_logloss: 0.00123287\tvalid_1's binary_logloss: 0.00844495\n",
      "[90]\ttraining's binary_logloss: 0.00110232\tvalid_1's binary_logloss: 0.0085042\n",
      "[100]\ttraining's binary_logloss: 0.000992145\tvalid_1's binary_logloss: 0.00856297\n",
      "[110]\ttraining's binary_logloss: 0.000893459\tvalid_1's binary_logloss: 0.008619\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.00324655\tvalid_1's binary_logloss: 0.00819778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0029529\tvalid_1's binary_logloss: 0.0144428\n",
      "[20]\ttraining's binary_logloss: 0.00221003\tvalid_1's binary_logloss: 0.0145691\n",
      "[30]\ttraining's binary_logloss: 0.00181431\tvalid_1's binary_logloss: 0.0146968\n",
      "[40]\ttraining's binary_logloss: 0.00154587\tvalid_1's binary_logloss: 0.0148294\n",
      "[50]\ttraining's binary_logloss: 0.0013411\tvalid_1's binary_logloss: 0.0149672\n",
      "[60]\ttraining's binary_logloss: 0.0011779\tvalid_1's binary_logloss: 0.0151094\n",
      "[70]\ttraining's binary_logloss: 0.00104274\tvalid_1's binary_logloss: 0.0152559\n",
      "[80]\ttraining's binary_logloss: 0.000928288\tvalid_1's binary_logloss: 0.0154063\n",
      "[90]\ttraining's binary_logloss: 0.000827992\tvalid_1's binary_logloss: 0.0155596\n",
      "[100]\ttraining's binary_logloss: 0.000742805\tvalid_1's binary_logloss: 0.0157166\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00536892\tvalid_1's binary_logloss: 0.0143093\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00535053\tvalid_1's binary_logloss: 0.00401176\n",
      "[20]\ttraining's binary_logloss: 0.00400278\tvalid_1's binary_logloss: 0.00398236\n",
      "[30]\ttraining's binary_logloss: 0.00308279\tvalid_1's binary_logloss: 0.00394106\n",
      "[40]\ttraining's binary_logloss: 0.00254376\tvalid_1's binary_logloss: 0.00389982\n",
      "[50]\ttraining's binary_logloss: 0.002174\tvalid_1's binary_logloss: 0.00386369\n",
      "[60]\ttraining's binary_logloss: 0.00189533\tvalid_1's binary_logloss: 0.00383435\n",
      "[70]\ttraining's binary_logloss: 0.00167695\tvalid_1's binary_logloss: 0.0038128\n",
      "[80]\ttraining's binary_logloss: 0.00149297\tvalid_1's binary_logloss: 0.00379642\n",
      "[90]\ttraining's binary_logloss: 0.00133546\tvalid_1's binary_logloss: 0.00378428\n",
      "[100]\ttraining's binary_logloss: 0.00119346\tvalid_1's binary_logloss: 0.0037636\n",
      "[110]\ttraining's binary_logloss: 0.0010709\tvalid_1's binary_logloss: 0.00374916\n",
      "[120]\ttraining's binary_logloss: 0.00096517\tvalid_1's binary_logloss: 0.00374455\n",
      "[130]\ttraining's binary_logloss: 0.000874305\tvalid_1's binary_logloss: 0.00374976\n",
      "[140]\ttraining's binary_logloss: 0.000794072\tvalid_1's binary_logloss: 0.003749\n",
      "[150]\ttraining's binary_logloss: 0.000721872\tvalid_1's binary_logloss: 0.0037557\n",
      "[160]\ttraining's binary_logloss: 0.000658533\tvalid_1's binary_logloss: 0.00376101\n",
      "[170]\ttraining's binary_logloss: 0.000600223\tvalid_1's binary_logloss: 0.00376383\n",
      "[180]\ttraining's binary_logloss: 0.000544498\tvalid_1's binary_logloss: 0.00377642\n",
      "[190]\ttraining's binary_logloss: 0.000495442\tvalid_1's binary_logloss: 0.00378746\n",
      "[200]\ttraining's binary_logloss: 0.00045226\tvalid_1's binary_logloss: 0.00380097\n",
      "[210]\ttraining's binary_logloss: 0.000412568\tvalid_1's binary_logloss: 0.00382021\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's binary_logloss: 0.000994704\tvalid_1's binary_logloss: 0.00374365\n",
      "categorical features:['cp_type', 'cp_dose']\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.043353\tvalid_1's binary_logloss: 0.0464645\n",
      "[20]\ttraining's binary_logloss: 0.0399427\tvalid_1's binary_logloss: 0.046515\n",
      "[30]\ttraining's binary_logloss: 0.036405\tvalid_1's binary_logloss: 0.0466024\n",
      "[40]\ttraining's binary_logloss: 0.033654\tvalid_1's binary_logloss: 0.0466842\n",
      "[50]\ttraining's binary_logloss: 0.0312517\tvalid_1's binary_logloss: 0.04674\n",
      "[60]\ttraining's binary_logloss: 0.0290284\tvalid_1's binary_logloss: 0.0466654\n",
      "[70]\ttraining's binary_logloss: 0.0271472\tvalid_1's binary_logloss: 0.0466287\n",
      "[80]\ttraining's binary_logloss: 0.0255658\tvalid_1's binary_logloss: 0.0465795\n",
      "[90]\ttraining's binary_logloss: 0.0240263\tvalid_1's binary_logloss: 0.0466182\n",
      "[100]\ttraining's binary_logloss: 0.0226572\tvalid_1's binary_logloss: 0.0466982\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's binary_logloss: 0.0458513\tvalid_1's binary_logloss: 0.0464362\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0457691\tvalid_1's binary_logloss: 0.0404036\n",
      "[20]\ttraining's binary_logloss: 0.0427754\tvalid_1's binary_logloss: 0.0403744\n",
      "[30]\ttraining's binary_logloss: 0.0396793\tvalid_1's binary_logloss: 0.0404116\n",
      "[40]\ttraining's binary_logloss: 0.0371417\tvalid_1's binary_logloss: 0.0404612\n",
      "[50]\ttraining's binary_logloss: 0.0351149\tvalid_1's binary_logloss: 0.0403855\n",
      "[60]\ttraining's binary_logloss: 0.0330498\tvalid_1's binary_logloss: 0.0403406\n",
      "[70]\ttraining's binary_logloss: 0.0310612\tvalid_1's binary_logloss: 0.0402338\n",
      "[80]\ttraining's binary_logloss: 0.02935\tvalid_1's binary_logloss: 0.0401928\n",
      "[90]\ttraining's binary_logloss: 0.027533\tvalid_1's binary_logloss: 0.0401259\n",
      "[100]\ttraining's binary_logloss: 0.0260016\tvalid_1's binary_logloss: 0.0401211\n",
      "[110]\ttraining's binary_logloss: 0.0246143\tvalid_1's binary_logloss: 0.0401127\n",
      "[120]\ttraining's binary_logloss: 0.0233597\tvalid_1's binary_logloss: 0.0401407\n",
      "[130]\ttraining's binary_logloss: 0.0220818\tvalid_1's binary_logloss: 0.040109\n",
      "[140]\ttraining's binary_logloss: 0.0209437\tvalid_1's binary_logloss: 0.0400855\n",
      "[150]\ttraining's binary_logloss: 0.0198428\tvalid_1's binary_logloss: 0.0400868\n",
      "[160]\ttraining's binary_logloss: 0.0189475\tvalid_1's binary_logloss: 0.0400878\n",
      "[170]\ttraining's binary_logloss: 0.0181072\tvalid_1's binary_logloss: 0.0400504\n",
      "[180]\ttraining's binary_logloss: 0.0173597\tvalid_1's binary_logloss: 0.0400304\n",
      "[190]\ttraining's binary_logloss: 0.0166478\tvalid_1's binary_logloss: 0.0400301\n",
      "[200]\ttraining's binary_logloss: 0.0159178\tvalid_1's binary_logloss: 0.0400366\n",
      "[210]\ttraining's binary_logloss: 0.0152244\tvalid_1's binary_logloss: 0.0400785\n",
      "[220]\ttraining's binary_logloss: 0.0147014\tvalid_1's binary_logloss: 0.040095\n",
      "[230]\ttraining's binary_logloss: 0.0141202\tvalid_1's binary_logloss: 0.0401391\n",
      "[240]\ttraining's binary_logloss: 0.0136356\tvalid_1's binary_logloss: 0.0401823\n",
      "[250]\ttraining's binary_logloss: 0.0131349\tvalid_1's binary_logloss: 0.0402508\n",
      "[260]\ttraining's binary_logloss: 0.0126236\tvalid_1's binary_logloss: 0.0402807\n",
      "[270]\ttraining's binary_logloss: 0.0121888\tvalid_1's binary_logloss: 0.0403345\n",
      "Early stopping, best iteration is:\n",
      "[179]\ttraining's binary_logloss: 0.0174391\tvalid_1's binary_logloss: 0.0400072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0409489\tvalid_1's binary_logloss: 0.0556135\n",
      "[20]\ttraining's binary_logloss: 0.037994\tvalid_1's binary_logloss: 0.0554476\n",
      "[30]\ttraining's binary_logloss: 0.0349369\tvalid_1's binary_logloss: 0.0553275\n",
      "[40]\ttraining's binary_logloss: 0.0319866\tvalid_1's binary_logloss: 0.0551632\n",
      "[50]\ttraining's binary_logloss: 0.0295882\tvalid_1's binary_logloss: 0.0551425\n",
      "[60]\ttraining's binary_logloss: 0.0275195\tvalid_1's binary_logloss: 0.0550104\n",
      "[70]\ttraining's binary_logloss: 0.0256661\tvalid_1's binary_logloss: 0.0549893\n",
      "[80]\ttraining's binary_logloss: 0.0239778\tvalid_1's binary_logloss: 0.0549362\n",
      "[90]\ttraining's binary_logloss: 0.0223035\tvalid_1's binary_logloss: 0.0549502\n",
      "[100]\ttraining's binary_logloss: 0.0209217\tvalid_1's binary_logloss: 0.0548995\n",
      "[110]\ttraining's binary_logloss: 0.0197215\tvalid_1's binary_logloss: 0.0549519\n",
      "[120]\ttraining's binary_logloss: 0.018685\tvalid_1's binary_logloss: 0.0549512\n",
      "[130]\ttraining's binary_logloss: 0.0177496\tvalid_1's binary_logloss: 0.0550201\n",
      "[140]\ttraining's binary_logloss: 0.0169334\tvalid_1's binary_logloss: 0.0550229\n",
      "[150]\ttraining's binary_logloss: 0.0161742\tvalid_1's binary_logloss: 0.0550125\n",
      "[160]\ttraining's binary_logloss: 0.0154227\tvalid_1's binary_logloss: 0.0550097\n",
      "[170]\ttraining's binary_logloss: 0.014733\tvalid_1's binary_logloss: 0.0549925\n",
      "[180]\ttraining's binary_logloss: 0.0140116\tvalid_1's binary_logloss: 0.0550692\n",
      "[190]\ttraining's binary_logloss: 0.0133333\tvalid_1's binary_logloss: 0.0551507\n",
      "[200]\ttraining's binary_logloss: 0.0127169\tvalid_1's binary_logloss: 0.0552543\n",
      "Early stopping, best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.0209217\tvalid_1's binary_logloss: 0.0548995\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.042949\tvalid_1's binary_logloss: 0.0464367\n",
      "[20]\ttraining's binary_logloss: 0.0393653\tvalid_1's binary_logloss: 0.0463703\n",
      "[30]\ttraining's binary_logloss: 0.0361435\tvalid_1's binary_logloss: 0.0464021\n",
      "[40]\ttraining's binary_logloss: 0.033033\tvalid_1's binary_logloss: 0.0463667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttraining's binary_logloss: 0.0305286\tvalid_1's binary_logloss: 0.0464546\n",
      "[60]\ttraining's binary_logloss: 0.0283965\tvalid_1's binary_logloss: 0.0465035\n",
      "[70]\ttraining's binary_logloss: 0.0265709\tvalid_1's binary_logloss: 0.0464856\n",
      "[80]\ttraining's binary_logloss: 0.0248943\tvalid_1's binary_logloss: 0.0464635\n",
      "[90]\ttraining's binary_logloss: 0.0232547\tvalid_1's binary_logloss: 0.0465283\n",
      "[100]\ttraining's binary_logloss: 0.0218308\tvalid_1's binary_logloss: 0.0466323\n",
      "[110]\ttraining's binary_logloss: 0.0206083\tvalid_1's binary_logloss: 0.0467206\n",
      "[120]\ttraining's binary_logloss: 0.0194806\tvalid_1's binary_logloss: 0.0467379\n",
      "[130]\ttraining's binary_logloss: 0.0185161\tvalid_1's binary_logloss: 0.0468061\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.03359\tvalid_1's binary_logloss: 0.0463203\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0446387\tvalid_1's binary_logloss: 0.0434546\n",
      "[20]\ttraining's binary_logloss: 0.0408885\tvalid_1's binary_logloss: 0.043352\n",
      "[30]\ttraining's binary_logloss: 0.0375947\tvalid_1's binary_logloss: 0.0433217\n",
      "[40]\ttraining's binary_logloss: 0.0346815\tvalid_1's binary_logloss: 0.0433154\n",
      "[50]\ttraining's binary_logloss: 0.0323763\tvalid_1's binary_logloss: 0.0431912\n",
      "[60]\ttraining's binary_logloss: 0.0302044\tvalid_1's binary_logloss: 0.0431948\n",
      "[70]\ttraining's binary_logloss: 0.0283763\tvalid_1's binary_logloss: 0.0431855\n",
      "[80]\ttraining's binary_logloss: 0.0266695\tvalid_1's binary_logloss: 0.0430948\n",
      "[90]\ttraining's binary_logloss: 0.0250497\tvalid_1's binary_logloss: 0.0431234\n",
      "[100]\ttraining's binary_logloss: 0.0235248\tvalid_1's binary_logloss: 0.0431707\n",
      "[110]\ttraining's binary_logloss: 0.0222792\tvalid_1's binary_logloss: 0.0430995\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2f8fdfbb4004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets_scored\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0m_oof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_lgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_oof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-227d7c26c9a0>\u001b[0m in \u001b[0;36mrun_lgbm\u001b[0;34m(X_train, X_test, target_col)\u001b[0m\n\u001b[1;32m     27\u001b[0m                                categorical_feature=object_cols)\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         model = lgb.train(params,\n\u001b[0m\u001b[1;32m     30\u001b[0m                           \u001b[0mlgb_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                           \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlgb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb_eval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/probspace_realestate/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/probspace_realestate/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for target_col in target_cols:\n",
    "    train_X = copy.deepcopy(train_features)\n",
    "    test_X = copy.deepcopy(test_features)\n",
    "    train_X, test_X = target_encoder(train_X, train_targets_scored[target_col], test_X, object_cols)\n",
    "    _oof, _preds = run_lgbm(train_X, test_X, target_col)\n",
    "    oof[target_col] = _oof\n",
    "    submission[target_col] = _preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for target_col in target_cols:\n",
    "    scores.append(log_loss(train_targets_scored[target_col], oof[target_col]))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug == False:\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        #'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        \"seed\":42,\n",
    "        \"learning_rate\":trial.suggest_loguniform('learning_rate', 0.005, 0.03),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "    }\n",
    "    FOLD_NUM = 5\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=FOLD_NUM, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    pred_cv = np.zeros(len(test.index))\n",
    "    num_round = 10000\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    for i, (tdx, vdx) in enumerate(kf.split(train_X[selected], train_y)):\n",
    "        print(f'Fold : {i}')\n",
    "        X_train, X_valid, y_train, y_valid = train_X[selected].iloc[tdx], train_X[selected].iloc[vdx], train_y.values[tdx], train_y.values[vdx]\n",
    "        lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=object_cols)\n",
    "        lgb_valid = lgb.Dataset(X_valid, y_valid, categorical_feature=object_cols)\n",
    "        model = lgb.train(params, lgb_train, num_boost_round=num_round,\n",
    "                      valid_names=[\"train\", \"valid\"], valid_sets=[lgb_train, lgb_valid],\n",
    "                      early_stopping_rounds=100, verbose_eval=10000)\n",
    "\n",
    "        va_pred = model.predict(X_valid)\n",
    "        va_pred[va_pred<0] = 0\n",
    "        score_ = np.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(va_pred)))\n",
    "        scores.append(score_)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の確認\n",
    "print('Best trial:')\n",
    "light_trial = study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(light_trial.value))\n",
    "\n",
    "print('  Params: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lightgbmparams.txt\", \"w\") as file:\n",
    "    for key, value in light_trial.params.items():\n",
    "       print('    \"{}\": {},'.format(key, value))\n",
    "       file.write('\"{}\": {},'.format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probspace_realestate",
   "language": "python",
   "name": "probspace_realestate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
