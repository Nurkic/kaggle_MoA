{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms-of-Action-Prediction-baseline-lightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "train_targets_scored = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "train_targets_nonscored = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "test_features = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "submission = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = pd.concat([train_features, test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "object_cols = [\"cp_type\", \"cp_dose\"]\n",
    "ce_oe = ce.OrdinalEncoder(cols=object_cols, handle_unknown='impute')\n",
    "prep_df = ce_oe.fit_transform(prep_df)\n",
    "train_features = prep_df.iloc[:len(train_features),:]\n",
    "test_features = prep_df.iloc[len(train_features):,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train models and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "FOLD_NUM = 5\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "target_cols = [c for c in train_targets_scored.columns if c != \"sig_id\"]\n",
    "oof = train_targets_scored.copy()\n",
    "num_round = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "#'boosting_type': 'gbdt',\n",
    "'objective': 'binary',\n",
    "#'lambda_l1': 0.001, \n",
    "#'lambda_l2': 0.001,\n",
    "'num_leaves': 50, \n",
    "'max_depth': 6,\n",
    "#'feature_fraction': 0.4,\n",
    "#'subsample': 0.4, \n",
    "#'min_child_samples': 10,\n",
    "'learning_rate': 0.01,\n",
    "#'num_iterations': 100, #700\n",
    "'early_stopping_rounds': 100,\n",
    "'random_state': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgbm(target_col: str):\n",
    "    \n",
    "    X_train = train_features.drop([\"sig_id\"], axis=1)\n",
    "    y_train = train_targets_scored[target_col]\n",
    "    X_test = test_features.drop([\"sig_id\"], axis=1)\n",
    "\n",
    "    y_preds = []\n",
    "    models = []\n",
    "    oof_train = np.zeros((len(X_train),))\n",
    "\n",
    "    for fold_id, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "        X_tr = X_train.loc[train_index, :]\n",
    "        X_val = X_train.loc[valid_index, :]\n",
    "        y_tr = y_train[train_index]\n",
    "        y_val = y_train[valid_index]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_tr,\n",
    "                                y_tr,\n",
    "                                categorical_feature=object_cols)\n",
    "\n",
    "        lgb_eval = lgb.Dataset(X_val,\n",
    "                               y_val,\n",
    "                               reference=lgb_train,\n",
    "                               categorical_feature=object_cols)\n",
    "\n",
    "        model = lgb.train(params,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_train, lgb_eval],\n",
    "                          verbose_eval=10,\n",
    "                          num_boost_round=1000,\n",
    "                          early_stopping_rounds=10)\n",
    "\n",
    "\n",
    "        oof_train[valid_index] = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        \n",
    "        y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "        models.append(model)\n",
    "\n",
    "    return oof_train, sum(y_preds) / len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimura_sampler/anaconda3/envs/probspace_realestate/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kimura_sampler/anaconda3/envs/probspace_realestate/lib/python3.8/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00236783\tvalid_1's binary_logloss: 0.0068585\n",
      "[20]\ttraining's binary_logloss: 0.00181572\tvalid_1's binary_logloss: 0.00688485\n",
      "[30]\ttraining's binary_logloss: 0.00150247\tvalid_1's binary_logloss: 0.00691576\n",
      "[40]\ttraining's binary_logloss: 0.00128277\tvalid_1's binary_logloss: 0.00695037\n",
      "[50]\ttraining's binary_logloss: 0.00111277\tvalid_1's binary_logloss: 0.00698997\n",
      "[60]\ttraining's binary_logloss: 0.000976128\tvalid_1's binary_logloss: 0.00702704\n",
      "[70]\ttraining's binary_logloss: 0.000863108\tvalid_1's binary_logloss: 0.00702334\n",
      "[80]\ttraining's binary_logloss: 0.00076729\tvalid_1's binary_logloss: 0.00703847\n",
      "[90]\ttraining's binary_logloss: 0.000684898\tvalid_1's binary_logloss: 0.00706433\n",
      "[100]\ttraining's binary_logloss: 0.000613379\tvalid_1's binary_logloss: 0.0070939\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00479453\tvalid_1's binary_logloss: 0.00681599\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00266577\tvalid_1's binary_logloss: 0.00530819\n",
      "[20]\ttraining's binary_logloss: 0.00202516\tvalid_1's binary_logloss: 0.0053103\n",
      "[30]\ttraining's binary_logloss: 0.00166892\tvalid_1's binary_logloss: 0.00531684\n",
      "[40]\ttraining's binary_logloss: 0.00142331\tvalid_1's binary_logloss: 0.0052905\n",
      "[50]\ttraining's binary_logloss: 0.00123901\tvalid_1's binary_logloss: 0.00529897\n",
      "[60]\ttraining's binary_logloss: 0.0010892\tvalid_1's binary_logloss: 0.00529756\n",
      "[70]\ttraining's binary_logloss: 0.000964934\tvalid_1's binary_logloss: 0.00529569\n",
      "[80]\ttraining's binary_logloss: 0.000859801\tvalid_1's binary_logloss: 0.00529897\n",
      "[90]\ttraining's binary_logloss: 0.000768595\tvalid_1's binary_logloss: 0.00531232\n",
      "[100]\ttraining's binary_logloss: 0.000688966\tvalid_1's binary_logloss: 0.00532944\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00528055\tvalid_1's binary_logloss: 0.00528727\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00233804\tvalid_1's binary_logloss: 0.00841953\n",
      "[20]\ttraining's binary_logloss: 0.00175009\tvalid_1's binary_logloss: 0.00847221\n",
      "[30]\ttraining's binary_logloss: 0.00143684\tvalid_1's binary_logloss: 0.00851535\n",
      "[40]\ttraining's binary_logloss: 0.00121976\tvalid_1's binary_logloss: 0.00850614\n",
      "[50]\ttraining's binary_logloss: 0.00105637\tvalid_1's binary_logloss: 0.00853672\n",
      "[60]\ttraining's binary_logloss: 0.00092529\tvalid_1's binary_logloss: 0.00858954\n",
      "[70]\ttraining's binary_logloss: 0.000816531\tvalid_1's binary_logloss: 0.00863357\n",
      "[80]\ttraining's binary_logloss: 0.000724518\tvalid_1's binary_logloss: 0.00868252\n",
      "[90]\ttraining's binary_logloss: 0.000645269\tvalid_1's binary_logloss: 0.00874113\n",
      "[100]\ttraining's binary_logloss: 0.000576258\tvalid_1's binary_logloss: 0.00878061\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00472976\tvalid_1's binary_logloss: 0.0083773\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00241597\tvalid_1's binary_logloss: 0.00687358\n",
      "[20]\ttraining's binary_logloss: 0.00184332\tvalid_1's binary_logloss: 0.00690013\n",
      "[30]\ttraining's binary_logloss: 0.00152531\tvalid_1's binary_logloss: 0.00687355\n",
      "[40]\ttraining's binary_logloss: 0.00130226\tvalid_1's binary_logloss: 0.00688003\n",
      "[50]\ttraining's binary_logloss: 0.00113028\tvalid_1's binary_logloss: 0.00688626\n",
      "[60]\ttraining's binary_logloss: 0.000991331\tvalid_1's binary_logloss: 0.00690091\n",
      "[70]\ttraining's binary_logloss: 0.000876557\tvalid_1's binary_logloss: 0.00685615\n",
      "[80]\ttraining's binary_logloss: 0.000779177\tvalid_1's binary_logloss: 0.00684577\n",
      "[90]\ttraining's binary_logloss: 0.000695429\tvalid_1's binary_logloss: 0.00685286\n",
      "[100]\ttraining's binary_logloss: 0.000622206\tvalid_1's binary_logloss: 0.00685347\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00492669\tvalid_1's binary_logloss: 0.00682253\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00312568\tvalid_1's binary_logloss: 0.0023157\n",
      "[20]\ttraining's binary_logloss: 0.00235044\tvalid_1's binary_logloss: 0.00223158\n",
      "[30]\ttraining's binary_logloss: 0.00193929\tvalid_1's binary_logloss: 0.00214333\n",
      "[40]\ttraining's binary_logloss: 0.00164909\tvalid_1's binary_logloss: 0.00203242\n",
      "[50]\ttraining's binary_logloss: 0.00143636\tvalid_1's binary_logloss: 0.00199205\n",
      "[60]\ttraining's binary_logloss: 0.00126565\tvalid_1's binary_logloss: 0.00195835\n",
      "[70]\ttraining's binary_logloss: 0.00112336\tvalid_1's binary_logloss: 0.0019231\n",
      "[80]\ttraining's binary_logloss: 0.00100243\tvalid_1's binary_logloss: 0.00188688\n",
      "[90]\ttraining's binary_logloss: 0.000898261\tvalid_1's binary_logloss: 0.00185417\n",
      "[100]\ttraining's binary_logloss: 0.000807622\tvalid_1's binary_logloss: 0.00182007\n",
      "[110]\ttraining's binary_logloss: 0.000728009\tvalid_1's binary_logloss: 0.00178444\n",
      "[120]\ttraining's binary_logloss: 0.000657705\tvalid_1's binary_logloss: 0.00176787\n",
      "[130]\ttraining's binary_logloss: 0.000595284\tvalid_1's binary_logloss: 0.00174853\n",
      "[140]\ttraining's binary_logloss: 0.00053973\tvalid_1's binary_logloss: 0.00173698\n",
      "[150]\ttraining's binary_logloss: 0.000490007\tvalid_1's binary_logloss: 0.00172259\n",
      "[160]\ttraining's binary_logloss: 0.000445489\tvalid_1's binary_logloss: 0.00171516\n",
      "[170]\ttraining's binary_logloss: 0.000405191\tvalid_1's binary_logloss: 0.00170934\n",
      "[180]\ttraining's binary_logloss: 0.000368818\tvalid_1's binary_logloss: 0.00170556\n",
      "[190]\ttraining's binary_logloss: 0.000336219\tvalid_1's binary_logloss: 0.00170751\n",
      "[200]\ttraining's binary_logloss: 0.000306652\tvalid_1's binary_logloss: 0.00170644\n",
      "[210]\ttraining's binary_logloss: 0.000279342\tvalid_1's binary_logloss: 0.00170601\n",
      "[220]\ttraining's binary_logloss: 0.00025425\tvalid_1's binary_logloss: 0.00171509\n",
      "[230]\ttraining's binary_logloss: 0.000231921\tvalid_1's binary_logloss: 0.00172543\n",
      "[240]\ttraining's binary_logloss: 0.000211479\tvalid_1's binary_logloss: 0.00173231\n",
      "[250]\ttraining's binary_logloss: 0.000192801\tvalid_1's binary_logloss: 0.0017442\n",
      "[260]\ttraining's binary_logloss: 0.000175966\tvalid_1's binary_logloss: 0.00175276\n",
      "[270]\ttraining's binary_logloss: 0.000160702\tvalid_1's binary_logloss: 0.0017662\n",
      "[280]\ttraining's binary_logloss: 0.000146807\tvalid_1's binary_logloss: 0.00178039\n",
      "[290]\ttraining's binary_logloss: 0.000134095\tvalid_1's binary_logloss: 0.00179513\n",
      "[300]\ttraining's binary_logloss: 0.000122724\tvalid_1's binary_logloss: 0.00180644\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's binary_logloss: 0.000298454\tvalid_1's binary_logloss: 0.00170035\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00319751\tvalid_1's binary_logloss: 0.00509385\n",
      "[20]\ttraining's binary_logloss: 0.00234229\tvalid_1's binary_logloss: 0.00506767\n",
      "[30]\ttraining's binary_logloss: 0.00195541\tvalid_1's binary_logloss: 0.00506711\n",
      "[40]\ttraining's binary_logloss: 0.00168903\tvalid_1's binary_logloss: 0.00505298\n",
      "[50]\ttraining's binary_logloss: 0.00148022\tvalid_1's binary_logloss: 0.00501904\n",
      "[60]\ttraining's binary_logloss: 0.00130957\tvalid_1's binary_logloss: 0.00500147\n",
      "[70]\ttraining's binary_logloss: 0.00116683\tvalid_1's binary_logloss: 0.00500943\n",
      "[80]\ttraining's binary_logloss: 0.00104485\tvalid_1's binary_logloss: 0.00501546\n",
      "[90]\ttraining's binary_logloss: 0.000936985\tvalid_1's binary_logloss: 0.00503625\n",
      "[100]\ttraining's binary_logloss: 0.000844957\tvalid_1's binary_logloss: 0.00504492\n",
      "[110]\ttraining's binary_logloss: 0.000766001\tvalid_1's binary_logloss: 0.00505825\n",
      "[120]\ttraining's binary_logloss: 0.000697763\tvalid_1's binary_logloss: 0.00505574\n",
      "[130]\ttraining's binary_logloss: 0.000636548\tvalid_1's binary_logloss: 0.00507055\n",
      "[140]\ttraining's binary_logloss: 0.000581244\tvalid_1's binary_logloss: 0.00509213\n",
      "[150]\ttraining's binary_logloss: 0.000529541\tvalid_1's binary_logloss: 0.00511992\n",
      "[160]\ttraining's binary_logloss: 0.000482513\tvalid_1's binary_logloss: 0.00514963\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.00129487\tvalid_1's binary_logloss: 0.00499701\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00243123\tvalid_1's binary_logloss: 0.00997034\n",
      "[20]\ttraining's binary_logloss: 0.00179818\tvalid_1's binary_logloss: 0.0100447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttraining's binary_logloss: 0.00148971\tvalid_1's binary_logloss: 0.0100949\n",
      "[40]\ttraining's binary_logloss: 0.0012776\tvalid_1's binary_logloss: 0.0101784\n",
      "[50]\ttraining's binary_logloss: 0.00111616\tvalid_1's binary_logloss: 0.0102491\n",
      "[60]\ttraining's binary_logloss: 0.000984331\tvalid_1's binary_logloss: 0.010325\n",
      "[70]\ttraining's binary_logloss: 0.00087552\tvalid_1's binary_logloss: 0.0103921\n",
      "[80]\ttraining's binary_logloss: 0.000782081\tvalid_1's binary_logloss: 0.0104816\n",
      "[90]\ttraining's binary_logloss: 0.000700959\tvalid_1's binary_logloss: 0.0105739\n",
      "[100]\ttraining's binary_logloss: 0.000629586\tvalid_1's binary_logloss: 0.0106743\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.0049334\tvalid_1's binary_logloss: 0.00992439\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0030805\tvalid_1's binary_logloss: 0.00686536\n",
      "[20]\ttraining's binary_logloss: 0.00219902\tvalid_1's binary_logloss: 0.00685029\n",
      "[30]\ttraining's binary_logloss: 0.00183716\tvalid_1's binary_logloss: 0.00685923\n",
      "[40]\ttraining's binary_logloss: 0.00158376\tvalid_1's binary_logloss: 0.00686736\n",
      "[50]\ttraining's binary_logloss: 0.00139098\tvalid_1's binary_logloss: 0.00689111\n",
      "[60]\ttraining's binary_logloss: 0.00123492\tvalid_1's binary_logloss: 0.00690651\n",
      "[70]\ttraining's binary_logloss: 0.00110157\tvalid_1's binary_logloss: 0.00695243\n",
      "[80]\ttraining's binary_logloss: 0.000988369\tvalid_1's binary_logloss: 0.00700128\n",
      "[90]\ttraining's binary_logloss: 0.000889985\tvalid_1's binary_logloss: 0.00704696\n",
      "[100]\ttraining's binary_logloss: 0.000801903\tvalid_1's binary_logloss: 0.00710008\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00524522\tvalid_1's binary_logloss: 0.00681002\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00297344\tvalid_1's binary_logloss: 0.00533101\n",
      "[20]\ttraining's binary_logloss: 0.00222886\tvalid_1's binary_logloss: 0.00533069\n",
      "[30]\ttraining's binary_logloss: 0.00185928\tvalid_1's binary_logloss: 0.00527883\n",
      "[40]\ttraining's binary_logloss: 0.0015979\tvalid_1's binary_logloss: 0.00528996\n",
      "[50]\ttraining's binary_logloss: 0.00139096\tvalid_1's binary_logloss: 0.00529406\n",
      "[60]\ttraining's binary_logloss: 0.00123008\tvalid_1's binary_logloss: 0.00530502\n",
      "[70]\ttraining's binary_logloss: 0.00109703\tvalid_1's binary_logloss: 0.00532791\n",
      "[80]\ttraining's binary_logloss: 0.00098445\tvalid_1's binary_logloss: 0.00535444\n",
      "[90]\ttraining's binary_logloss: 0.000886706\tvalid_1's binary_logloss: 0.00538352\n",
      "[100]\ttraining's binary_logloss: 0.000801526\tvalid_1's binary_logloss: 0.00541013\n",
      "[110]\ttraining's binary_logloss: 0.000726021\tvalid_1's binary_logloss: 0.00543939\n",
      "[120]\ttraining's binary_logloss: 0.000659792\tvalid_1's binary_logloss: 0.00547124\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.00189006\tvalid_1's binary_logloss: 0.00527782\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00334651\tvalid_1's binary_logloss: 0.00380979\n",
      "[20]\ttraining's binary_logloss: 0.00250412\tvalid_1's binary_logloss: 0.0037916\n",
      "[30]\ttraining's binary_logloss: 0.00209423\tvalid_1's binary_logloss: 0.0037771\n",
      "[40]\ttraining's binary_logloss: 0.00180027\tvalid_1's binary_logloss: 0.00376465\n",
      "[50]\ttraining's binary_logloss: 0.0015782\tvalid_1's binary_logloss: 0.00375661\n",
      "[60]\ttraining's binary_logloss: 0.00139683\tvalid_1's binary_logloss: 0.00375261\n",
      "[70]\ttraining's binary_logloss: 0.0012449\tvalid_1's binary_logloss: 0.00373131\n",
      "[80]\ttraining's binary_logloss: 0.00111768\tvalid_1's binary_logloss: 0.00372171\n",
      "[90]\ttraining's binary_logloss: 0.00100955\tvalid_1's binary_logloss: 0.00371145\n",
      "[100]\ttraining's binary_logloss: 0.000915396\tvalid_1's binary_logloss: 0.00371549\n",
      "[110]\ttraining's binary_logloss: 0.00083249\tvalid_1's binary_logloss: 0.00372254\n",
      "[120]\ttraining's binary_logloss: 0.00075887\tvalid_1's binary_logloss: 0.00372697\n",
      "[130]\ttraining's binary_logloss: 0.000693146\tvalid_1's binary_logloss: 0.00373406\n",
      "[140]\ttraining's binary_logloss: 0.000634211\tvalid_1's binary_logloss: 0.00374777\n",
      "[150]\ttraining's binary_logloss: 0.000580336\tvalid_1's binary_logloss: 0.00375828\n",
      "[160]\ttraining's binary_logloss: 0.000530467\tvalid_1's binary_logloss: 0.00376968\n",
      "[170]\ttraining's binary_logloss: 0.00048435\tvalid_1's binary_logloss: 0.00377811\n",
      "[180]\ttraining's binary_logloss: 0.000441789\tvalid_1's binary_logloss: 0.00379673\n",
      "[190]\ttraining's binary_logloss: 0.00040362\tvalid_1's binary_logloss: 0.00381283\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's binary_logloss: 0.000970535\tvalid_1's binary_logloss: 0.00370958\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00468045\tvalid_1's binary_logloss: 0.00831409\n",
      "[20]\ttraining's binary_logloss: 0.00337409\tvalid_1's binary_logloss: 0.00835909\n",
      "[30]\ttraining's binary_logloss: 0.00261703\tvalid_1's binary_logloss: 0.00839134\n",
      "[40]\ttraining's binary_logloss: 0.00223781\tvalid_1's binary_logloss: 0.00843131\n",
      "[50]\ttraining's binary_logloss: 0.00194761\tvalid_1's binary_logloss: 0.00847403\n",
      "[60]\ttraining's binary_logloss: 0.00171315\tvalid_1's binary_logloss: 0.00852051\n",
      "[70]\ttraining's binary_logloss: 0.00151758\tvalid_1's binary_logloss: 0.00857129\n",
      "[80]\ttraining's binary_logloss: 0.00135838\tvalid_1's binary_logloss: 0.00862718\n",
      "[90]\ttraining's binary_logloss: 0.00122568\tvalid_1's binary_logloss: 0.00868206\n",
      "[100]\ttraining's binary_logloss: 0.00110629\tvalid_1's binary_logloss: 0.00873411\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00705367\tvalid_1's binary_logloss: 0.00826747\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.00508694\tvalid_1's binary_logloss: 0.00542899\n",
      "[20]\ttraining's binary_logloss: 0.00371302\tvalid_1's binary_logloss: 0.00543063\n",
      "[30]\ttraining's binary_logloss: 0.00294543\tvalid_1's binary_logloss: 0.00541671\n",
      "[40]\ttraining's binary_logloss: 0.00249621\tvalid_1's binary_logloss: 0.0054039\n",
      "[50]\ttraining's binary_logloss: 0.00217577\tvalid_1's binary_logloss: 0.00539852\n",
      "[60]\ttraining's binary_logloss: 0.00192056\tvalid_1's binary_logloss: 0.00539718\n",
      "[70]\ttraining's binary_logloss: 0.00170489\tvalid_1's binary_logloss: 0.00540009\n",
      "[80]\ttraining's binary_logloss: 0.00152518\tvalid_1's binary_logloss: 0.00540859\n",
      "[90]\ttraining's binary_logloss: 0.00137024\tvalid_1's binary_logloss: 0.00542118\n",
      "[100]\ttraining's binary_logloss: 0.0012334\tvalid_1's binary_logloss: 0.00543718\n",
      "[110]\ttraining's binary_logloss: 0.00111666\tvalid_1's binary_logloss: 0.00545754\n",
      "[120]\ttraining's binary_logloss: 0.00100998\tvalid_1's binary_logloss: 0.0054804\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-ec0dac81867b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtarget_col\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0m_oof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_lgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_oof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-7680a9b80bca>\u001b[0m in \u001b[0;36mrun_lgbm\u001b[0;34m(target_col)\u001b[0m\n\u001b[1;32m     24\u001b[0m                                categorical_feature=object_cols)\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         model = lgb.train(params,\n\u001b[0m\u001b[1;32m     27\u001b[0m                           \u001b[0mlgb_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                           \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlgb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb_eval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/probspace_realestate/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/probspace_realestate/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for target_col in target_cols:\n",
    "    _oof, _preds = run_lgbm(target_col)\n",
    "    oof[target_col] = _oof\n",
    "    submission[target_col] = _preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for target_col in target_cols:\n",
    "    scores.append(log_loss(train_targets_scored[target_col], oof[target_col]))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug == False:\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        #'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        \"seed\":42,\n",
    "        \"learning_rate\":trial.suggest_loguniform('learning_rate', 0.005, 0.03),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "    }\n",
    "    FOLD_NUM = 5\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=FOLD_NUM, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    pred_cv = np.zeros(len(test.index))\n",
    "    num_round = 10000\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    for i, (tdx, vdx) in enumerate(kf.split(train_X[selected], train_y)):\n",
    "        print(f'Fold : {i}')\n",
    "        X_train, X_valid, y_train, y_valid = train_X[selected].iloc[tdx], train_X[selected].iloc[vdx], train_y.values[tdx], train_y.values[vdx]\n",
    "        lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=object_cols)\n",
    "        lgb_valid = lgb.Dataset(X_valid, y_valid, categorical_feature=object_cols)\n",
    "        model = lgb.train(params, lgb_train, num_boost_round=num_round,\n",
    "                      valid_names=[\"train\", \"valid\"], valid_sets=[lgb_train, lgb_valid],\n",
    "                      early_stopping_rounds=100, verbose_eval=10000)\n",
    "\n",
    "        va_pred = model.predict(X_valid)\n",
    "        va_pred[va_pred<0] = 0\n",
    "        score_ = np.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(va_pred)))\n",
    "        scores.append(score_)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の確認\n",
    "print('Best trial:')\n",
    "light_trial = study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(light_trial.value))\n",
    "\n",
    "print('  Params: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lightgbmparams.txt\", \"w\") as file:\n",
    "    for key, value in light_trial.params.items():\n",
    "       print('    \"{}\": {},'.format(key, value))\n",
    "       file.write('\"{}\": {},'.format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probspace_realestate",
   "language": "python",
   "name": "probspace_realestate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
