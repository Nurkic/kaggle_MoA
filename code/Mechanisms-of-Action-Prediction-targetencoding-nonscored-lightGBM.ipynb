{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms-of-Action-Prediction-targetencoding-featureselection-lightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import lightgbm as lgb\n",
    "#import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "train_targets_scored = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "train_targets_nonscored = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "test_features = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "submission = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = pd.concat([train_features, test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "object_cols = [\"cp_type\", \"cp_dose\"]\n",
    "ce_oe = ce.OrdinalEncoder(cols=object_cols, handle_unknown='impute')\n",
    "prep_df = ce_oe.fit_transform(prep_df)\n",
    "train_features = prep_df.iloc[:len(train_features),:]\n",
    "test_features = prep_df.iloc[len(train_features):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    'fungal_1,3-beta-d-glucan_synthase_inhibitor': 'fungal_1_3-beta_d_glucan_synthase_inhibitor',\n",
    "    'glutathione_reductase_(nadph)_activators': 'glutathione_reductase_nadph_activators',\n",
    "    'h+_k+-atpase_inhibitor': 'h_k_atpase_inhibitor',\n",
    "    'indoleamine_2,3-dioxygenase_inhibitor': 'indoleamine_2_3_dioxygenase_inhibitor',\n",
    "    'mitochondrial_na+_ca2+_exchanger_antagonist': 'mitochondrial_na_ca2_exchanger_antagonist',\n",
    "    'nociceptin_orphanin_fq_(nop)_receptor_antagonist': 'nociceptin_orphanin_fq_nop_receptor_antagonist',\n",
    "    'sars_coronavirus_3c-like_protease_inhibitor': 'sars_coronavirus_3c_like_protease_inhibitor',\n",
    "    'selective_estrogen_receptor_modulator_(serm)': 'selective_estrogen_receptor_modulator_serm',\n",
    "    'selective_serotonin_reuptake_inhibitor_(ssri)': 'selective_serotonin_reuptake_inhibitor_ssri',\n",
    "    'sterol_regulatory_element_binding_protein_(srebp)_inhibitor': 'sterol_regulatory_element_binding_protein_srebp_inhibitor'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_nonscored.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoder(\n",
    "        train_X: pd.DataFrame,\n",
    "        train_y: pd.DataFrame,\n",
    "        test: pd.DataFrame,\n",
    "        column_list: list\n",
    ") -> pd.DataFrame:\n",
    "        train_X_te = copy.deepcopy(train_X)\n",
    "        test_X_te = copy.deepcopy(test)\n",
    "        if len(column_list) > 0:\n",
    "            print(\"categorical features:\"+ str(column_list))\n",
    "        else:\n",
    "            print(\"No categorical features\")\n",
    "        for c in column_list:\n",
    "            data_tmp = pd.DataFrame({c: train_X_te[c], \"target\": train_y})\n",
    "            target_mean = data_tmp.groupby(c)[\"target\"].mean()\n",
    "            \"\"\" print(target_mean)\"\"\"\n",
    "            test_X_te[c] = test_X_te[c].map(target_mean).astype(float)\n",
    "\n",
    "            tmp = np.repeat(np.nan, train_X.shape[0])\n",
    "            kf_encoding = KFold(n_splits=4, shuffle=True, random_state=72)\n",
    "            for idx_1, idx_2 in kf_encoding.split(train_X_te):\n",
    "                target_mean = data_tmp.iloc[idx_1].groupby(c)[\"target\"].mean()\n",
    "\n",
    "                tmp[idx_2] = train_X_te[c].iloc[idx_2].map(target_mean)\n",
    "\n",
    "            train_X_te[c] = tmp\n",
    "\n",
    "        return train_X_te, test_X_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "FOLD_NUM = 5\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "target_cols_scored = [c for c in train_targets_scored.columns if c != \"sig_id\"]\n",
    "target_cols_nonscored = [c for c in train_targets_nonscored.columns if c != \"sig_id\"]\n",
    "oof_scored = train_targets_scored.copy()\n",
    "test_targets_nonscored = pd.DataFrame()\n",
    "test_targets_nonscored[\"sig_id\"] = test_features[\"sig_id\"]\n",
    "num_round = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "#'boosting_type': 'gbdt',\n",
    "'objective': 'binary',\n",
    "#'lambda_l1': 0.001, \n",
    "#'lambda_l2': 0.001,\n",
    "'num_leaves': 24, \n",
    "'max_depth': 5,\n",
    "#'feature_fraction': 0.4,\n",
    "#'subsample': 0.4, \n",
    "#'min_child_samples': 10,\n",
    "'learning_rate': 0.01,\n",
    "#'num_iterations': 100, #700\n",
    "#'early_stopping_rounds': 100,\n",
    "'random_state': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgbm(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    target_col: str):\n",
    "    \n",
    "    X_train = X_train.drop([\"sig_id\"], axis=1)\n",
    "    y_train = y_train[target_col]\n",
    "    X_test = X_test.drop([\"sig_id\"], axis=1)\n",
    "\n",
    "    y_preds = []\n",
    "    models = []\n",
    "    oof_train = np.zeros((len(X_train),))\n",
    "\n",
    "    for fold_id, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "        X_tr = X_train.loc[train_index, :]\n",
    "        X_val = X_train.loc[valid_index, :]\n",
    "        y_tr = y_train[train_index]\n",
    "        y_val = y_train[valid_index]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_tr,\n",
    "                                y_tr,\n",
    "                                categorical_feature=object_cols)\n",
    "\n",
    "        lgb_eval = lgb.Dataset(X_val,\n",
    "                               y_val,\n",
    "                               reference=lgb_train,\n",
    "                               categorical_feature=object_cols)\n",
    "\n",
    "        model = lgb.train(params,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_train, lgb_eval],\n",
    "                          verbose_eval=10,\n",
    "                          num_boost_round=1000,\n",
    "                          early_stopping_rounds=10)\n",
    "\n",
    "\n",
    "        oof_train[valid_index] = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        \n",
    "        #y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "        #y_preds.append(y_pred)\n",
    "        #models.append(model)\n",
    "        \n",
    "        if debug == False:\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "            y_preds.append(y_pred)\n",
    "            models.append(model)\n",
    "            #file = \"trained_lgbm\" + str(fold_id) + \".pkl\"\n",
    "            #pickle.dump(model, open(file, \"wb\"))\n",
    "            model.save_model(\"trained_lgbm\" + str(fold_id) + \".tc\")\n",
    "            del model\n",
    "\n",
    "            return oof_train, sum(y_preds) / len(y_preds), y_preds\n",
    "        \n",
    "        else:\n",
    "            return oof_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train nonscored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if debug == False:\n",
    "    for target_col in target_cols_nonscored:\n",
    "        train_X = copy.deepcopy(train_features)\n",
    "        test_X = copy.deepcopy(test_features)\n",
    "        train_X, test_X = target_encoder(train_X, train_targets_nonscored[target_col], test_X, object_cols)\n",
    "    \n",
    "        _, _, _preds  = run_lgbm(train_X, test_X, train_targets_nonscored, target_col)\n",
    "        test_targets_nonscored[target_col] = _preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.concat([train_features, train_targets_nonscored.drop([\"sig_id\"], axis=1)], axis=1)\n",
    "test_features = pd.concat([train_features, test_targets_nonscored.drop([\"sig_id\"], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>ve-cadherin_antagonist</th>\n",
       "      <th>vesicular_monoamine_transporter_inhibitor</th>\n",
       "      <th>vitamin_k_antagonist</th>\n",
       "      <th>voltage-gated_calcium_channel_ligand</th>\n",
       "      <th>voltage-gated_potassium_channel_activator</th>\n",
       "      <th>voltage-gated_sodium_channel_blocker</th>\n",
       "      <th>wdr5_mll_interaction_inhibitor</th>\n",
       "      <th>wnt_agonist</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 1278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  cp_type  cp_time  cp_dose     g-0     g-1     g-2  \\\n",
       "0      id_000644bb2        1       24        1  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc        1       72        1  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a        1       48        1  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391        1       48        1 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3        1       72        2 -0.3254 -0.4009  0.9700   \n",
       "...             ...      ...      ...      ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed        1       24        2  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c        1       24        2 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4        2       48        2  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c        1       24        1  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b        1       72        1 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "          g-3     g-4     g-5  ...  ve-cadherin_antagonist  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ...                       0   \n",
       "1      0.0604  1.0190  0.5207  ...                       0   \n",
       "2     -0.0764 -0.0323  1.2390  ...                       0   \n",
       "3      0.5288  4.0620 -0.8095  ...                       0   \n",
       "4      0.6919  1.4180 -0.8244  ...                       0   \n",
       "...       ...     ...     ...  ...                     ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ...                       0   \n",
       "23810  0.9905 -0.7178  0.6621  ...                       0   \n",
       "23811 -0.7389  0.5505 -0.0159  ...                       0   \n",
       "23812  0.2044  0.8531 -0.0343  ...                       0   \n",
       "23813  0.7952 -0.3611 -3.6750  ...                       0   \n",
       "\n",
       "       vesicular_monoamine_transporter_inhibitor  vitamin_k_antagonist  \\\n",
       "0                                              0                     0   \n",
       "1                                              0                     0   \n",
       "2                                              0                     0   \n",
       "3                                              0                     0   \n",
       "4                                              0                     0   \n",
       "...                                          ...                   ...   \n",
       "23809                                          0                     0   \n",
       "23810                                          0                     0   \n",
       "23811                                          0                     0   \n",
       "23812                                          0                     0   \n",
       "23813                                          0                     0   \n",
       "\n",
       "       voltage-gated_calcium_channel_ligand  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "...                                     ...   \n",
       "23809                                     0   \n",
       "23810                                     0   \n",
       "23811                                     0   \n",
       "23812                                     0   \n",
       "23813                                     0   \n",
       "\n",
       "       voltage-gated_potassium_channel_activator  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "...                                          ...   \n",
       "23809                                          0   \n",
       "23810                                          0   \n",
       "23811                                          0   \n",
       "23812                                          0   \n",
       "23813                                          0   \n",
       "\n",
       "       voltage-gated_sodium_channel_blocker  wdr5_mll_interaction_inhibitor  \\\n",
       "0                                         0                               0   \n",
       "1                                         0                               0   \n",
       "2                                         0                               0   \n",
       "3                                         0                               0   \n",
       "4                                         0                               0   \n",
       "...                                     ...                             ...   \n",
       "23809                                     0                               0   \n",
       "23810                                     0                               0   \n",
       "23811                                     0                               0   \n",
       "23812                                     0                               0   \n",
       "23813                                     0                               0   \n",
       "\n",
       "       wnt_agonist  xanthine_oxidase_inhibitor  xiap_inhibitor  \n",
       "0                0                           0               0  \n",
       "1                0                           0               0  \n",
       "2                0                           0               0  \n",
       "3                0                           0               0  \n",
       "4                0                           0               0  \n",
       "...            ...                         ...             ...  \n",
       "23809            0                           0               0  \n",
       "23810            0                           0               0  \n",
       "23811            0                           0               0  \n",
       "23812            0                           0               0  \n",
       "23813            0                           0               0  \n",
       "\n",
       "[23814 rows x 1278 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical features:['cp_type', 'cp_dose']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macuser/anaconda3/envs/salary_pred/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13, number of negative: 19038\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.392261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222460\n",
      "[LightGBM] [Info] Number of data points in the train set: 19051, number of used features: 922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macuser/anaconda3/envs/salary_pred/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Users/macuser/anaconda3/envs/salary_pred/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000682 -> initscore=-7.289243\n",
      "[LightGBM] [Info] Start training from score -7.289243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttraining's binary_logloss: 0.00236524\tvalid_1's binary_logloss: 0.00686287\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00482727\tvalid_1's binary_logloss: 0.00681477\n",
      "categorical features:['cp_type', 'cp_dose']\n",
      "[LightGBM] [Info] Number of positive: 15, number of negative: 19036\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.446486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222460\n",
      "[LightGBM] [Info] Number of data points in the train set: 19051, number of used features: 922\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000787 -> initscore=-7.146037\n",
      "[LightGBM] [Info] Start training from score -7.146037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttraining's binary_logloss: 0.00364074\tvalid_1's binary_logloss: 0.00394242\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\ttraining's binary_logloss: 0.00285419\tvalid_1's binary_logloss: 0.00372177\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\ttraining's binary_logloss: 0.00238986\tvalid_1's binary_logloss: 0.00360839\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\ttraining's binary_logloss: 0.00196898\tvalid_1's binary_logloss: 0.00351986\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\ttraining's binary_logloss: 0.00170846\tvalid_1's binary_logloss: 0.00350067\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.00190719\tvalid_1's binary_logloss: 0.00348995\n",
      "categorical features:['cp_type', 'cp_dose']\n",
      "[LightGBM] [Info] Number of positive: 19, number of negative: 19032\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.381671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222460\n",
      "[LightGBM] [Info] Number of data points in the train set: 19051, number of used features: 922\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000997 -> initscore=-6.909438\n",
      "[LightGBM] [Info] Start training from score -6.909438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttraining's binary_logloss: 0.00487376\tvalid_1's binary_logloss: 0.00830827\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.00707917\tvalid_1's binary_logloss: 0.0082669\n",
      "categorical features:['cp_type', 'cp_dose']\n",
      "[LightGBM] [Info] Number of positive: 152, number of negative: 18899\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.437671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222460\n",
      "[LightGBM] [Info] Number of data points in the train set: 19051, number of used features: 922\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.007979 -> initscore=-4.822984\n",
      "[LightGBM] [Info] Start training from score -4.822984\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttraining's binary_logloss: 0.0447976\tvalid_1's binary_logloss: 0.0464188\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e05e2115b068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0m_oof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_lgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets_scored\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moof_scored\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_oof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-674ff8493354>\u001b[0m in \u001b[0;36mrun_lgbm\u001b[0;34m(X_train, y_train, X_test, target_col)\u001b[0m\n\u001b[1;32m     33\u001b[0m                           \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                           early_stopping_rounds=10)\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/salary_pred/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/salary_pred/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2370\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2371\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for target_col in target_cols_scored:\n",
    "    train_X = copy.deepcopy(train_features)\n",
    "    test_X = copy.deepcopy(test_features)\n",
    "    train_X, test_X = target_encoder(train_X, train_targets_scored[target_col], test_X, object_cols)\n",
    "    if debug == False:\n",
    "        _oof, _preds, _ = run_lgbm(train_X, train_targets_scored, test_X, target_col)\n",
    "        oof_scored[target_col] = _oof\n",
    "        submission[target_col] = _preds\n",
    "    else:\n",
    "        _oof = run_lgbm(train_X, train_targets_scored, test_X, target_col)\n",
    "        oof_scored[target_col] = _oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for target_col in target_cols_scored:\n",
    "    scores.append(log_loss(train_targets_scored[target_col], oof_scored[target_col]))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug == False:\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_salary_pred)",
   "language": "python",
   "name": "conda_salary_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
